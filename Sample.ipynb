{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sciences po final assingments\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "install the required packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting minet\n",
      "  Using cached minet-0.60.2-py3-none-any.whl (180 kB)\n",
      "Collecting tqdm>=4.60.0\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Collecting browser-cookie3==0.13.0\n",
      "  Using cached browser_cookie3-0.13.0-py3-none-any.whl\n",
      "Collecting urllib3[secure]<2,>=1.26.9\n",
      "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "Collecting json5>=0.8.5\n",
      "  Using cached json5-0.9.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cchardet>=2.1.7\n",
      "  Using cached cchardet-2.1.7-cp310-cp310-win_amd64.whl\n",
      "Collecting quenouille<2,>=1.4.2\n",
      "  Using cached quenouille-1.4.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: colorama>=0.4.0 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from minet) (0.4.4)\n",
      "Collecting ebbe<2,>=1.3.1\n",
      "  Using cached ebbe-1.8.0-py3-none-any.whl (10 kB)\n",
      "Collecting trafilatura<1.3,>=1.2.0\n",
      "  Using cached trafilatura-1.2.0-py3-none-any.whl (194 kB)\n",
      "Collecting casanova<0.18,>=0.17.1\n",
      "  Using cached casanova-0.17.1-py3-none-any.whl (20 kB)\n",
      "Collecting termcolor>=1.0.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting pyyaml\n",
      "  Using cached PyYAML-6.0-cp310-cp310-win_amd64.whl (151 kB)\n",
      "Collecting twitwi<0.11,>=0.10.3\n",
      "  Using cached twitwi-0.10.3-py3-none-any.whl (16 kB)\n",
      "Collecting keyring<19.3\n",
      "  Using cached keyring-19.2.0-py2.py3-none-any.whl (34 kB)\n",
      "Collecting lxml>=4.3.0\n",
      "  Using cached lxml-4.8.0-cp310-cp310-win_amd64.whl (3.6 MB)\n",
      "Collecting ndjson>=0.3.1\n",
      "  Using cached ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
      "Collecting ural<0.33,>=0.32.0\n",
      "  Using cached ural-0.32.1-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.7.1 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from minet) (4.11.1)\n",
      "Collecting dateparser>=1.1.1\n",
      "  Using cached dateparser-1.1.1-py2.py3-none-any.whl (288 kB)\n",
      "Collecting persist-queue>=0.7.0\n",
      "  Using cached persist_queue-0.7.0-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: soupsieve>=2.1 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from minet) (2.3.2.post1)\n",
      "Collecting tenacity>=7.0.0\n",
      "  Using cached tenacity-8.0.1-py3-none-any.whl (24 kB)\n",
      "Collecting pbkdf2\n",
      "  Using cached pbkdf2-1.3-py3-none-any.whl\n",
      "Collecting pycryptodome\n",
      "  Using cached pycryptodome-3.14.1-cp35-abi3-win_amd64.whl (1.8 MB)\n",
      "Collecting SecretStorage\n",
      "  Using cached SecretStorage-3.3.2-py3-none-any.whl (15 kB)\n",
      "Collecting lz4\n",
      "  Using cached lz4-4.0.0-cp310-cp310-win_amd64.whl (96 kB)\n",
      "Collecting pyaes\n",
      "  Using cached pyaes-1.6.1-py3-none-any.whl\n",
      "Collecting file-read-backwards<3,>=2.0.0\n",
      "  Using cached file_read_backwards-2.0.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting regex!=2019.02.19,!=2021.8.27,<2022.3.15\n",
      "  Using cached regex-2022.3.2-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Collecting pytz\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting tzlocal\n",
      "  Using cached tzlocal-4.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from dateparser>=1.1.1->minet) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from keyring<19.3->minet) (0.4)\n",
      "Collecting pywin32-ctypes!=0.1.0,!=0.1.1\n",
      "  Using cached pywin32_ctypes-0.2.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting htmldate>=1.1.1\n",
      "  Using cached htmldate-1.2.1-py3-none-any.whl (37 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
      "Collecting charset-normalizer>=2.0.12\n",
      "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Collecting courlan>=0.6.0\n",
      "  Using cached courlan-0.7.1-py3-none-any.whl (37 kB)\n",
      "Collecting justext>=3.0.0\n",
      "  Using cached jusText-3.0.0-py2.py3-none-any.whl (837 kB)\n",
      "Collecting twitter==2.0a0\n",
      "  Using cached twitter-2.0a0-py2.py3-none-any.whl (52 kB)\n",
      "Collecting tld<1,>=0.12.1\n",
      "  Using cached tld-0.12.6-py39-none-any.whl (412 kB)\n",
      "Collecting pycountry<19,>=18.12.8\n",
      "  Using cached pycountry-18.12.8-py2.py3-none-any.whl (10.5 MB)\n",
      "Collecting phylactery<0.3,>=0.2.3\n",
      "  Using cached phylactery-0.2.3-py3-none-any.whl (7.3 kB)\n",
      "Collecting cryptography>=1.3.4\n",
      "  Using cached cryptography-37.0.1-cp36-abi3-win_amd64.whl (2.4 MB)\n",
      "Collecting pyOpenSSL>=0.14\n",
      "  Using cached pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "Collecting idna>=2.0.0\n",
      "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
      "Collecting langcodes>=3.3.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from cryptography>=1.3.4->urllib3[secure]<2,>=1.26.9->minet) (1.15.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from python-dateutil->dateparser>=1.1.1->minet) (1.16.0)\n",
      "Collecting jeepney>=0.6\n",
      "  Using cached jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "Collecting pytz-deprecation-shim\n",
      "  Using cached pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tzdata\n",
      "  Using cached tzdata-2022.1-py2.py3-none-any.whl (339 kB)\n",
      "Requirement already satisfied: pycparser in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]<2,>=1.26.9->minet) (2.21)\n",
      "Installing collected packages: tzdata, pytz-deprecation-shim, tzlocal, regex, pytz, urllib3, tld, pywin32-ctypes, pycountry, phylactery, lxml, langcodes, jeepney, dateparser, cryptography, charset-normalizer, ural, twitter, SecretStorage, pyOpenSSL, pycryptodome, pyaes, pbkdf2, lz4, keyring, justext, idna, htmldate, file-read-backwards, ebbe, courlan, certifi, twitwi, trafilatura, tqdm, termcolor, tenacity, quenouille, pyyaml, persist-queue, ndjson, json5, cchardet, casanova, browser-cookie3, minet\n",
      "Successfully installed SecretStorage-3.3.2 browser-cookie3-0.13.0 casanova-0.17.1 cchardet-2.1.7 certifi-2021.10.8 charset-normalizer-2.0.12 courlan-0.7.1 cryptography-37.0.1 dateparser-1.1.1 ebbe-1.8.0 file-read-backwards-2.0.0 htmldate-1.2.1 idna-3.3 jeepney-0.8.0 json5-0.9.6 justext-3.0.0 keyring-19.2.0 langcodes-3.3.0 lxml-4.8.0 lz4-4.0.0 minet-0.60.2 ndjson-0.3.1 pbkdf2-1.3 persist-queue-0.7.0 phylactery-0.2.3 pyOpenSSL-22.0.0 pyaes-1.6.1 pycountry-18.12.8 pycryptodome-3.14.1 pytz-2022.1 pytz-deprecation-shim-0.1.0.post0 pywin32-ctypes-0.2.0 pyyaml-6.0 quenouille-1.4.2 regex-2022.3.2 tenacity-8.0.1 termcolor-1.1.0 tld-0.12.6 tqdm-4.64.0 trafilatura-1.2.0 twitter-2.0a0 twitwi-0.10.3 tzdata-2022.1 tzlocal-4.2 ural-0.32.1 urllib3-1.26.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Code\\SciencesPoFinalAssignment\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ural in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (0.32.1)\n",
      "Requirement already satisfied: pycountry<19,>=18.12.8 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from ural) (18.12.8)\n",
      "Requirement already satisfied: phylactery<0.3,>=0.2.3 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from ural) (0.2.3)\n",
      "Requirement already satisfied: tld<1,>=0.12.1 in c:\\code\\sciencespofinalassignment\\venv\\lib\\site-packages (from ural) (0.12.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Code\\SciencesPoFinalAssignment\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "!pip install minet\n",
    "!pip install ural\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scrape the tweets\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "from minet.twitter import TwitterAPIScraper\n",
    "import itertools\n",
    "\n",
    "def chunks(iterable, size=100):\n",
    "    \"\"\"Chunks a\n",
    "     generator into a blocks of size n\"\"\"\n",
    "    iterator = iter(iterable)\n",
    "    for first in iterator:\n",
    "        yield itertools.chain([first], itertools.islice(iterator, size - 1))\n",
    "\n",
    "def get_tweets():\n",
    "    scraper = TwitterAPIScraper()\n",
    "    chunk_size=100\n",
    "    def identity_with_logging(i,x):\n",
    "        print(i)\n",
    "        return x\n",
    "    tweetStream = scraper.search_tweets('(blocage OR occupation) sciencespo')\n",
    "    return [tweet for i, hundred in enumerate(chunks(tweetStream,chunk_size)) for tweet in identity_with_logging(chunk_size*(i+1),list(hundred))]\n",
    "\n",
    "tweets = get_tweets()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get most retweeted tweet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "\"text: 💥📣OCCUPATION EN COURS A SCIENCES PO !  \\nAprès l' #ENS et la #Sorbonne, c'est au tour des étudiant-es de SciencesPo à #Paris de se mobiliser. \\nNi Le Pen, ni Macron, contre la précarité, le déni écologique et la violation des droits humains, la jeunesse s'organise ! https://twitter.com/sarah_chp/status/1514499001948774403/photo/1 \\nauthor: sarah_chp \\nretweets: 361\""
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_tweet = max(tweets, key=lambda t : t['retweet_count'])\n",
    "print(f\"text: {top_tweet['text']} \\nauthor: {top_tweet['user_screen_name']} \\nretweets: {top_tweet['retweet_count']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get top ten most represented accounts in our corpus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import reduce # import needed for python3; builtin in python2\n",
    "from collections import defaultdict\n",
    "\n",
    "def group(key, seq):\n",
    "    return reduce(lambda grp, val: grp[key(val)].append(val) or grp, seq, defaultdict(list))\n",
    "\n",
    "grouped_by_user_name = group(lambda x : x[\"user_screen_name\"], tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "[('sciencespo', 19),\n ('MatthDes', 18),\n ('DavidLibeau', 17),\n ('LaPeniche', 15),\n ('ubellier', 15),\n ('SieurHibou', 11),\n ('st3vK', 8),\n ('wnewspresse', 7),\n ('ActusNonStop', 6),\n ('unisciencespo', 6)]"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10 = sorted(grouped_by_user_name.items(), key=lambda x : -len(x[1]))[:10]\n",
    "[(key,len(value)) for key,value in top10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the top ten users by retweet count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "[('sarah_chp', 361),\n ('Anton1Ferreira', 350),\n ('RemyBuisine', 296),\n ('LarrereMathilde', 290),\n ('sciencespo', 272),\n ('LesNews', 239),\n ('LEtudiant_Libre', 223),\n ('Valeurs', 199),\n ('InsoumisJeunes', 181),\n ('UrsusArctos92', 166)]"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retweet_counts = [(username,sum([tweet['retweet_count'] for tweet in tweets])) for username,tweets in grouped_by_user_name.items()]\n",
    "top10_total_retweets = sorted(retweet_counts, key=lambda x : -x[1])[:10]\n",
    "top10_total_retweets\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : 0, max : 361, mean : 5.396591789310612, median : 0 stdev : 23.210612131240275\n"
     ]
    }
   ],
   "source": [
    "from statistics import median,mean,stdev\n",
    "retweet_counts = [x['retweet_count'] for x in tweets]\n",
    "print(f\"min : {min(retweet_counts)}, max : {max(retweet_counts)}, mean : {mean(retweet_counts)}, median : {median(retweet_counts)} stdev : {stdev(retweet_counts)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "import csv\n",
    "rows = [{\"url\" : key, \"count\" : len(val)}  for key,val in group(lambda x : x, [link for tweet in tweets for link in tweet['links'] ]).items()]\n",
    "with open(\"./zeru_komary_k_snidani.csv\", \"w\", newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['url','count'])\n",
    "    writer.writerows(rows)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get 10 most shared links"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'url': 'http://www.lemonde.fr/enseignement-superieur/article/2013/02/27/sciences-po-occupation-d-un-amphi-contre-la-procedure-de-succession_1840022_1473692.html',\n  'count': 19},\n {'url': 'https://youtu.be/hPzR5g-sdoU', 'count': 18},\n {'url': 'https://www.huffingtonpost.fr/2018/04/18/blocage-a-sciencespo-reconnaitrez-vous-la-replique-de-film-culte-citee-par-cet-etudiant_a_23414065/',\n  'count': 12},\n {'url': 'http://www.lemonde.fr/campus/article/2018/04/20/a-sciences-po-paris-le-blocage-etudiant-leve-apres-des-negociations_5288336_4401467.html',\n  'count': 10},\n {'url': 'https://www.ouest-france.fr/education/universites/blocage-des-universites-sciences-po-bloque-paris-et-rennes-5705238',\n  'count': 7},\n {'url': 'http://lemde.fr/13Z0Vjv', 'count': 7},\n {'url': 'https://www.leparisien.fr/elections/presidentielle/presidentielle-occupation-de-la-sorbonne-lens-a-paris-et-de-sciences-po-nancy-par-des-etudiants-en-colere-13-04-2022-MP76WOAVI5ANVISJ7ELSFONBGE.phpnull',\n  'count': 6},\n {'url': 'http://www.revolutionpermanente.fr/L-occupation-de-Sciences-Po-Toulouse-votee-a-une-ecrasante-majorite',\n  'count': 6},\n {'url': 'https://ift.tt/2HeHazG', 'count': 6},\n {'url': 'http://www.bfmtv.com/societe/partiels-bouscules-a-nanterre-occupation-a-sciences-po-paris-le-point-sur-les-blocages-des-universites-1421816.html',\n  'count': 6}]"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_shared10 = sorted(rows, key=lambda x : -x['count'])\n",
    "most_shared10[:10]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "['sciencespo',\n 'blocage',\n 'nuitdebout',\n 'periscope',\n 'paris',\n 'occupation',\n 'loitravail',\n 'agsciencespo',\n 'sorbonne',\n 'blocus',\n 'rennes',\n 'occupyscpo',\n 'toulouse',\n 'tolbiac',\n 'occupyboutmy',\n 'macron',\n 'giletsjaunes',\n 'sciencespofacoccupee',\n 'agloitravail',\n 'sciences',\n 'nonalaselection',\n 'lgophilippot',\n 'étudiants',\n 'unef',\n 'grenoble']"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x : x[0], sorted(group(lambda x : x, [hashtag for tweet in tweets for hashtag in tweet['hashtags']]).items(), key=lambda x : -len(x[1]))))[:25]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}